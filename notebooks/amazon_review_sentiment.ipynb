{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "import json\n",
    "import string\n",
    "import gzip\n",
    "import h5py\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(context='notebook', style='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = './data/'\n",
    "\n",
    "# Storing paths of datasets in dictionary for convenience\n",
    "DATA = {\n",
    "    'fashion': path + 'AMAZON_FASHION_5.json.gz',\n",
    "    'movies': path + 'Movies_and_TV_5.json.gz',\n",
    "    'dictionary': path + 'dictionary.json',\n",
    "    'words': path + 'words.txt',\n",
    "    'cleaned': path + 'cleaned_amazon_reviews.json',\n",
    "    'cleaned_fashion': path + 'cleaned_amazon_fashion_5.json',\n",
    "    'amazon_data': path + 'amazon_reviews.hdf5'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist_dict():\n",
    "    \"\"\"\n",
    "    Storing a dictionary of all english words\n",
    "    along with their index in json file\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(DATA['words'], 'r') as dictionary:\n",
    "        all_words = {line.strip('\\n').lower(): ind for ind, line in enumerate(dictionary)}\n",
    "        all_words['UNK'] = -1\n",
    "    \n",
    "    with open(DATA['dictionary'], 'w+') as persist:\n",
    "        json.dump(all_words, persist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all review text and ratings\n",
    "def extract_reviews(files, cleaned_file=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    Extracting all review text and ratings\n",
    "    from persistent json file. Write to a\n",
    "    json file. Files are gzip.\n",
    "    \n",
    "    \"\"\"\n",
    "    if cleaned_file == None:\n",
    "        cleaned_file = 'cleaned_' + file\n",
    "        \n",
    "    with open(cleaned_file, 'w+') as persist:\n",
    "        for file in files:\n",
    "            with gzip.open(file) as data:\n",
    "                for review in data:\n",
    "                    review = json.loads(review)\n",
    "                    if 'reviewText' not in review:\n",
    "                        continue\n",
    "                    score = review['overall']\n",
    "                    review_text = review['reviewText']\n",
    "                    review_json = {'overall': score, 'reviewText': review_text}\n",
    "                    persist.write(json.dumps(review_json) + '\\n')\n",
    "                \n",
    "    return f'file saved at {os.getcwd()}/{cleaned_file}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_hdf5(file, dset_name, arr=None, readfile=None):\n",
    "    with h5py.File(file, 'w') as persist:\n",
    "        if arr:\n",
    "            persist.create_dataset(dset_name, data=arr)\n",
    "            return\n",
    "        if readfile:\n",
    "            with gzip.open(readfile, 'r') as f:\n",
    "                ratings_dset = dset_name + \"_ratings\"\n",
    "                corpus_dset = dset_name + \"_review_text\"\n",
    "                dt = h5py.string_dtype()\n",
    "                file_size = sum((1 for line in f))\n",
    "                \n",
    "                # Creating datasets for ratings and review corpora\n",
    "                persist.create_dataset(\n",
    "                    ratings_dset,\n",
    "                    shape=(file_size, 1),\n",
    "                    maxshape=(None),\n",
    "                    chunks=(1000, 1),\n",
    "                    dtype=np.float,\n",
    "                    #compression='gzip',\n",
    "                    #compression_opts=0\n",
    "                )\n",
    "                \n",
    "                persist.create_dataset(\n",
    "                    corpus_dset,\n",
    "                    shape=(file_size, 1),\n",
    "                    maxshape=(None),\n",
    "                    chunks=(1000, 1),\n",
    "                    dtype=dt,\n",
    "                )\n",
    "                \n",
    "                f.seek(0) # reset cursor at start of file\n",
    "                \n",
    "                for ind, review in enumerate(f):\n",
    "                    review = json.loads(review)\n",
    "                    if 'reviewText' not in review:\n",
    "                        continue\n",
    "                    rating = np.asarray(review['overall']).astype(np.float)\n",
    "                    corpus = np.asarray(review['reviewText'])\n",
    "                    persist[ratings_dset][ind] = rating\n",
    "                    persist[corpus_dset][ind] = corpus\n",
    "                    \n",
    "    return f'File written at {os.path.join(os.getcwd(), file)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'File written at /Users/derekhuynh/programming/sentiment_naive/./data/fashion_reviews.hdf5'"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_hdf5('./data/fashion_reviews.hdf5', 'fashion', readfile=DATA['fashion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'File written at /Users/derekhuynh/programming/sentiment_naive/./data/amazon_reviews.hdf5'"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store_hdf5('./data/movies_reviews.hdf5', 'movies', readfile=DATA['movies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_files = [\n",
    "    #DATA['fashion'], \n",
    "    #DATA['movies'],\n",
    "#]\n",
    "\n",
    "#test_reviews = extract_reviews(\n",
    "    #data_files,\n",
    "    #cleaned_file=f\"./data/cleaned_amazon_reviews.json\"\n",
    "    #)\n",
    "#test_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divergence here with the files, cleaned_fashion has the text as arrays while the one with the movies has it as\n",
    "raw corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_array(file):\n",
    "    \"\"\"\n",
    "    Creating feature vectors of ratings\n",
    "    annd review text from cleaned json files.\n",
    "    Saving the arrays in an hdf5 file.\n",
    "    \n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    review_text = []\n",
    "    with gzip.open(file) as f:\n",
    "        for review in f:\n",
    "            review = json.loads(review)\n",
    "            if 'reviewText' not in review:\n",
    "                continue\n",
    "            rating = np.asarray(review['overall']).astype(np.float)\n",
    "            corpus = np.asarray(review['reviewText'])\n",
    "            review_text.append(corpus)\n",
    "            scores.append(rating)\n",
    "            \n",
    "    scores = np.asarray(scores).astype(np.float).reshape(-1,1)\n",
    "    review_text = np.asarray(review_text).reshape(-1,1)\n",
    "    \n",
    "    return np.core.records.fromarrays([scores, review_text], names='ratings,review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec.array([[(5., 'Great product and price!')],\n",
       "           [(5., 'Great product and price!')],\n",
       "           [(5., 'Great product and price!')],\n",
       "           ...,\n",
       "           [(5., 'Love them fit perfect')],\n",
       "           [(5., \"Favorite Nike shoe ever! The flex sole is excellent for someone like me who loves the free feeling of sandals or being barefoot. These move effortlessly with the bend of my foot. I've worn these for multiple activities and I've had no foot or ankle pain. The white/green/dark grey color goes with so many outfits and the mesh breathes perfectly on hot summer days. Highly recommend!\")],\n",
       "           [(5., 'I wear these everyday to work, the gym, etc.')]],\n",
       "          dtype=[('ratings', '<f8'), ('review_text', '<U1366')])"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_reviews = _make_array(DATA['fashion'])\n",
    "fashion_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5.])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = fashion_reviews['ratings'].astype(np.float)\n",
    "uni = np.unique(ratings)\n",
    "uni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote> We now know that ratings only range from 1 - 5 </blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.4012658227848105"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ratings) # Generally more posistive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using word cloud, analyze the frequency\n",
    "# Of words in each review category\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "def make_word_cloud(arr):\n",
    "    stopwords = STOPWORDS\n",
    "    wc = []\n",
    "    for i in range(1, 6):\n",
    "        cond = arr['ratings'] == i\n",
    "        flat_corpus = np.concatenate(arr['review_text'][cond])\n",
    "        wordcl = WordCloud(collocations=False).generate(' '.join(flat_corpus.tolist()))\n",
    "        wc.append(wordcl)\n",
    "    fig, axes = plt.subplots(5, figsize=(30,30))\n",
    "    ind = 0\n",
    "    for ax in axes:\n",
    "        ax.imshow(wc[ind])\n",
    "        ax.set_title(f'Rating : {ind+1}')\n",
    "        ind += 1\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-345-450b8cf1e01d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_word_cloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfashion_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-344-217391c57817>\u001b[0m in \u001b[0;36mmake_word_cloud\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ratings'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mflat_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mwordcl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollocations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_corpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mwc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordcl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "make_word_cloud(fashion_reviews).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote> The frequency of the word \"shoe\" points to the fact that there are a majority of reviews pertaining\n",
    "    to shoes. We should keep this in mind when training our models </blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can categorize the five ratings into those that best represent their sentiments. Ratings of 1 and 2 are the\n",
    "most negative and should contain very strong sentiment. They will be labeled as \"negative\" or 0.\n",
    "A rating of 3 is the closest to the average, while not being overly negative or positive.\n",
    "These ratings will be labeled as \"neutral\" or 1. Ratings of 4 and 5 should be the ones with the most positivity,\n",
    "with maybe only a few criticisms. Therefore these ratings should be categorized as \"positive\" sentiment or 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_reviews(arr):\n",
    "     return ' '.join(arr.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vfunc = np.vectorize(join_reviews)\n",
    "#docs = vfunc(fashion_reviews['review_text']).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = fashion_reviews['review_text'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing using count vectorizers\n",
    "# And inverse document frequency\n",
    "pipe = Pipeline([('counts', CountVectorizer()),\n",
    "                ('idf', TfidfTransformer())]).fit(docs)\n",
    "X_train = pipe.fit_transform(docs) # This will simply chain the two transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'great': 521,\n",
       " 'product': 947,\n",
       " 'and': 74,\n",
       " 'price': 940,\n",
       " 'waaay': 1368,\n",
       " 'too': 1301,\n",
       " 'small': 1133,\n",
       " 'will': 1428,\n",
       " 'use': 1350,\n",
       " 'for': 475,\n",
       " 'futur': 492,\n",
       " 'children': 218,\n",
       " 'stays': 1191,\n",
       " 'vibrant': 1364,\n",
       " 'after': 55,\n",
       " 'many': 729,\n",
       " 'washes': 1386,\n",
       " 'my': 773,\n",
       " 'son': 1154,\n",
       " 'really': 980,\n",
       " 'likes': 681,\n",
       " 'the': 1255,\n",
       " 'pink': 905,\n",
       " 'ones': 830,\n",
       " 'which': 1417,\n",
       " 'was': 1384,\n",
       " 'nervous': 784,\n",
       " 'about': 28,\n",
       " 'future': 493,\n",
       " 'child': 217,\n",
       " 'relieved': 998,\n",
       " 'plantar': 914,\n",
       " 'fascitis': 428,\n",
       " 'days': 310,\n",
       " 'then': 1258,\n",
       " 'unbearable': 1337,\n",
       " 'pain': 867,\n",
       " 'returned': 1017,\n",
       " 'in': 599,\n",
       " 'full': 489,\n",
       " 'force': 476,\n",
       " 'these': 1261,\n",
       " 'were': 1410,\n",
       " 'recommended': 989,\n",
       " 'by': 188,\n",
       " 'podiatrist': 924,\n",
       " 'this': 1272,\n",
       " 'is': 618,\n",
       " '6th': 21,\n",
       " 'pair': 869,\n",
       " 'they': 1262,\n",
       " 'are': 89,\n",
       " 'best': 139,\n",
       " 'thing': 1268,\n",
       " 'ever': 392,\n",
       " 'fasciitis': 427,\n",
       " 'resultant': 1014,\n",
       " 'neuromas': 785,\n",
       " 'unfortunately': 1341,\n",
       " 'ordered': 842,\n",
       " 'from': 486,\n",
       " 'smartdestination': 1135,\n",
       " 'must': 772,\n",
       " 'be': 124,\n",
       " 'seconds': 1065,\n",
       " 'as': 96,\n",
       " 'kill': 642,\n",
       " 'feet': 438,\n",
       " 'hard': 543,\n",
       " 'plastic': 915,\n",
       " 'insert': 607,\n",
       " 'rubs': 1043,\n",
       " 'on': 827,\n",
       " 'outside': 856,\n",
       " 'edges': 367,\n",
       " 'of': 815,\n",
       " 'am': 69,\n",
       " 'unable': 1336,\n",
       " 'to': 1293,\n",
       " 'exchange': 404,\n",
       " 'them': 1257,\n",
       " 'waited': 1370,\n",
       " 'one': 829,\n",
       " 'day': 309,\n",
       " 'late': 658,\n",
       " 'walking': 1373,\n",
       " 'shoes': 1094,\n",
       " 'we': 1393,\n",
       " 'have': 549,\n",
       " 'used': 1351,\n",
       " 'inserts': 608,\n",
       " 'years': 1459,\n",
       " 'provide': 953,\n",
       " 'support': 1222,\n",
       " 'pinnacle': 909,\n",
       " 'seems': 1070,\n",
       " 'more': 759,\n",
       " 'cushioning': 295,\n",
       " 'so': 1140,\n",
       " 'husband': 590,\n",
       " 'better': 140,\n",
       " 'he': 552,\n",
       " 'tried': 1320,\n",
       " 'all': 61,\n",
       " 'other': 847,\n",
       " 'powerstep': 932,\n",
       " 'well': 1408,\n",
       " 'brands': 167,\n",
       " 'his': 569,\n",
       " 'weighs': 1402,\n",
       " '257lbs': 11,\n",
       " 'with': 1433,\n",
       " 'bone': 154,\n",
       " 'spurs': 1172,\n",
       " 'high': 561,\n",
       " 'instep': 614,\n",
       " 'very': 1361,\n",
       " 'active': 42,\n",
       " 'wears': 1397,\n",
       " 'rarely': 971,\n",
       " 'bother': 158,\n",
       " 'him': 567,\n",
       " 'any': 78,\n",
       " 'remember': 1001,\n",
       " 'replace': 1003,\n",
       " 'every': 393,\n",
       " 'months': 758,\n",
       " 'if': 592,\n",
       " 'you': 1465,\n",
       " 'wear': 1394,\n",
       " 'especially': 386,\n",
       " 'weigh': 1401,\n",
       " 'than': 1252,\n",
       " 'average': 105,\n",
       " 'or': 839,\n",
       " 'run': 1044,\n",
       " 'excellent': 401,\n",
       " 'insole': 610,\n",
       " 'good': 514,\n",
       " 'little': 688,\n",
       " 'cushion': 293,\n",
       " 'protech': 952,\n",
       " 'but': 185,\n",
       " 'arch': 87,\n",
       " 'maybe': 735,\n",
       " 'just': 636,\n",
       " 'lower': 713,\n",
       " 'love': 708,\n",
       " 'both': 157,\n",
       " 'styles': 1210,\n",
       " 'insoles': 611,\n",
       " 'help': 558,\n",
       " 'heels': 556,\n",
       " 'feel': 435,\n",
       " 'much': 768,\n",
       " 'would': 1452,\n",
       " 'never': 786,\n",
       " 'athletic': 101,\n",
       " 'original': 844,\n",
       " 'waaaay': 1367,\n",
       " 'big': 142,\n",
       " 'comfortable': 248,\n",
       " 'though': 1274,\n",
       " 'sizes': 1116,\n",
       " 'tend': 1247,\n",
       " 'bigger': 143,\n",
       " 'based': 122,\n",
       " 'mens': 740,\n",
       " 'size': 1114,\n",
       " 'think': 1270,\n",
       " 'there': 1260,\n",
       " 'wasn': 1388,\n",
       " 'chart': 212,\n",
       " 'refer': 991,\n",
       " 'when': 1414,\n",
       " 'ordering': 843,\n",
       " 'ended': 376,\n",
       " 'up': 1345,\n",
       " 'buying': 187,\n",
       " 'two': 1331,\n",
       " 'each': 362,\n",
       " 'at': 99,\n",
       " 'difference': 330,\n",
       " 'no': 795,\n",
       " 'problem': 945,\n",
       " 'fit': 454,\n",
       " 'even': 390,\n",
       " 'washing': 1387,\n",
       " 'hot': 576,\n",
       " 'water': 1390,\n",
       " 'shrinking': 1106,\n",
       " '30': 13,\n",
       " 'inch': 600,\n",
       " 'inseam': 606,\n",
       " '34': 14,\n",
       " 'waist': 1369,\n",
       " 'got': 517,\n",
       " 'medium': 738,\n",
       " 'note': 803,\n",
       " 'that': 1254,\n",
       " 'sweatpants': 1233,\n",
       " 'thick': 1264,\n",
       " 'not': 802,\n",
       " 'warm': 1383,\n",
       " 'climates': 230,\n",
       " 'quality': 967,\n",
       " 'value': 1356,\n",
       " 'typical': 1332,\n",
       " 'hanes': 537,\n",
       " 'weight': 1403,\n",
       " 'sized': 1115,\n",
       " 'right': 1023,\n",
       " 'made': 721,\n",
       " 'pretty': 938,\n",
       " 'string': 1206,\n",
       " 'broke': 176,\n",
       " 'first': 453,\n",
       " 'time': 1288,\n",
       " 'trying': 1325,\n",
       " 'luckily': 714,\n",
       " 'don': 348,\n",
       " 'need': 778,\n",
       " 'wast': 1389,\n",
       " 'it': 622,\n",
       " 'nice': 789,\n",
       " 'did': 327,\n",
       " 'break': 168,\n",
       " 'being': 134,\n",
       " 'said': 1050,\n",
       " 'pants': 871,\n",
       " 'expected': 411,\n",
       " 'probably': 944,\n",
       " 'shop': 1096,\n",
       " 'around': 93,\n",
       " 'next': 788,\n",
       " 'make': 724,\n",
       " 'sweatpant': 1232,\n",
       " 'purchase': 958,\n",
       " 'perfectly': 886,\n",
       " 'bought': 163,\n",
       " 'dark': 305,\n",
       " 'grey': 523,\n",
       " 'didn': 328,\n",
       " 'fade': 421,\n",
       " 'bad': 110,\n",
       " 'only': 832,\n",
       " 'give': 503,\n",
       " 'four': 481,\n",
       " 'stars': 1184,\n",
       " 'because': 129,\n",
       " 'pockets': 923,\n",
       " 'described': 322,\n",
       " 'comfy': 250,\n",
       " 'return': 1016,\n",
       " 'had': 533,\n",
       " 'theyd': 1263,\n",
       " 'awesome': 107,\n",
       " 'me': 736,\n",
       " 'lounge': 706,\n",
       " 'has': 544,\n",
       " 'stolen': 1198,\n",
       " 'might': 745,\n",
       " 'buy': 186,\n",
       " 'another': 77,\n",
       " 'terribly': 1251,\n",
       " 'disappointed': 338,\n",
       " 'way': 1391,\n",
       " 'large': 652,\n",
       " 'legs': 667,\n",
       " 'looked': 696,\n",
       " 'like': 679,\n",
       " 'wearing': 1396,\n",
       " 'blown': 150,\n",
       " 'clown': 237,\n",
       " 'home': 572,\n",
       " 'soft': 1143,\n",
       " 'switched': 1237,\n",
       " 'fruit': 488,\n",
       " 'loom': 699,\n",
       " 'somewhat': 1153,\n",
       " 'oversized': 861,\n",
       " 'huge': 584,\n",
       " 'bottom': 161,\n",
       " 'go': 509,\n",
       " 'over': 857,\n",
       " 'anything': 81,\n",
       " 'jeans': 629,\n",
       " 'ok': 821,\n",
       " 'lounging': 707,\n",
       " 'house': 579,\n",
       " 'em': 372,\n",
       " 'plain': 912,\n",
       " 'frills': 485,\n",
       " 'heavy': 554,\n",
       " 'ol': 823,\n",
       " 'havaiana': 548,\n",
       " 'perfect': 885,\n",
       " 'color': 240,\n",
       " 'should': 1100,\n",
       " 'listened': 686,\n",
       " 'reviews': 1021,\n",
       " 'elastics': 369,\n",
       " 'does': 345,\n",
       " 'hold': 571,\n",
       " 'constantly': 268,\n",
       " 'rolls': 1030,\n",
       " 'down': 350,\n",
       " 'superrrr': 1220,\n",
       " 'thigh': 1266,\n",
       " 'im': 593,\n",
       " '54': 20,\n",
       " 'easily': 364,\n",
       " 'reaches': 974,\n",
       " 'wish': 1432,\n",
       " 'roll': 1029,\n",
       " 'sadly': 1049,\n",
       " 'true': 1322,\n",
       " 'red': 990,\n",
       " 'definitely': 316,\n",
       " 'orange': 840,\n",
       " 'colorful': 242,\n",
       " 'gorgeous': 516,\n",
       " 'rich': 1022,\n",
       " 'fireman': 451,\n",
       " 'scarf': 1058,\n",
       " 'fella': 439,\n",
       " 'quite': 969,\n",
       " 'fashion': 429,\n",
       " 'plate': 916,\n",
       " 'toasty': 1294,\n",
       " 'work': 1443,\n",
       " 'sure': 1226,\n",
       " 'shipped': 1088,\n",
       " 'correct': 277,\n",
       " 'style': 1209,\n",
       " 'received': 984,\n",
       " 'lot': 704,\n",
       " 'clunkier': 238,\n",
       " 'although': 67,\n",
       " 'fine': 448,\n",
       " 'particularly': 877,\n",
       " 'since': 1109,\n",
       " 'lose': 703,\n",
       " 'reading': 976,\n",
       " 'glasses': 506,\n",
       " 'some': 1149,\n",
       " 'screws': 1062,\n",
       " 'do': 344,\n",
       " 'require': 1005,\n",
       " 'constant': 267,\n",
       " 'tightening': 1285,\n",
       " 'handy': 536,\n",
       " 'such': 1214,\n",
       " 'reasonable': 982,\n",
       " 'instead': 613,\n",
       " 'nose': 801,\n",
       " 'pieces': 903,\n",
       " 'find': 446,\n",
       " 'cheaper': 214,\n",
       " 'walmart': 1376,\n",
       " 'light': 675,\n",
       " 'shoe': 1092,\n",
       " 'add': 46,\n",
       " 'tennis': 1249,\n",
       " 'black': 146,\n",
       " 'dress': 355,\n",
       " 'comfort': 247,\n",
       " 'impressed': 597,\n",
       " 'flimsy': 465,\n",
       " 'nike': 793,\n",
       " 've': 1357,\n",
       " 'purchased': 959,\n",
       " 'past': 879,\n",
       " 'looks': 698,\n",
       " 'super': 1219,\n",
       " 'flexible': 463,\n",
       " 'training': 1314,\n",
       " 'definetly': 315,\n",
       " 'recommend': 988,\n",
       " 'excelente': 400,\n",
       " 'poorly': 928,\n",
       " 'constructed': 269,\n",
       " 'expect': 410,\n",
       " 'last': 655,\n",
       " 'summer': 1218,\n",
       " 'order': 841,\n",
       " 'downshifter': 351,\n",
       " 'series': 1074,\n",
       " 'again': 56,\n",
       " 'spent': 1161,\n",
       " 'say': 1056,\n",
       " 'doesn': 346,\n",
       " 'hurt': 587,\n",
       " 'always': 68,\n",
       " 'get': 499,\n",
       " 'half': 535,\n",
       " 'reason': 981,\n",
       " 'heel': 555,\n",
       " 'area': 90,\n",
       " 'wide': 1423,\n",
       " 'put': 965,\n",
       " 'walked': 1372,\n",
       " 'hours': 578,\n",
       " 'feeling': 436,\n",
       " 'stylish': 1211,\n",
       " 'back': 109,\n",
       " 'trip': 1321,\n",
       " 'nyc': 811,\n",
       " 'white': 1419,\n",
       " 'nikes': 794,\n",
       " 'yoga': 1464,\n",
       " 'now': 807,\n",
       " 'its': 625,\n",
       " 'expecting': 412,\n",
       " 'compared': 253,\n",
       " 'hope': 574,\n",
       " 'life': 672,\n",
       " 'out': 851,\n",
       " 'box': 164,\n",
       " '10': 1,\n",
       " 'pairs': 870,\n",
       " 'money': 756,\n",
       " 'pattern': 880,\n",
       " 'what': 1412,\n",
       " 'liked': 680,\n",
       " 'most': 760,\n",
       " 'least': 664,\n",
       " 'easy': 365,\n",
       " 'clean': 226,\n",
       " 'stains': 1179,\n",
       " 'come': 245,\n",
       " 'workout': 1446,\n",
       " 'times': 1289,\n",
       " 'week': 1399,\n",
       " 'gym': 532,\n",
       " 'treadmill': 1317,\n",
       " 'stairmaster': 1180,\n",
       " 'cardio': 200,\n",
       " 'classes': 225,\n",
       " 'lifting': 674,\n",
       " 'lightweight': 678,\n",
       " 'versatile': 1360,\n",
       " 'before': 132,\n",
       " 'been': 131,\n",
       " 'pleased': 919,\n",
       " 'performance': 888,\n",
       " 'online': 831,\n",
       " 'without': 1435,\n",
       " 'turned': 1327,\n",
       " 'choice': 219,\n",
       " 'breathable': 171,\n",
       " 'sturdy': 1208,\n",
       " 'during': 361,\n",
       " 'workouts': 1447,\n",
       " 'built': 180,\n",
       " 'discomfort': 340,\n",
       " 'weeks': 1400,\n",
       " 'far': 426,\n",
       " 'sole': 1145,\n",
       " 'thickness': 1265,\n",
       " 'goes': 510,\n",
       " 'consider': 262,\n",
       " 'build': 179,\n",
       " 'thin': 1267,\n",
       " 'overly': 859,\n",
       " 're': 973,\n",
       " 'into': 617,\n",
       " 'running': 1046,\n",
       " 'outdoors': 853,\n",
       " 'take': 1240,\n",
       " 'consideration': 263,\n",
       " 'everyone': 395,\n",
       " 'different': 331,\n",
       " 'their': 1256,\n",
       " 'preference': 933,\n",
       " 'runs': 1047,\n",
       " 'sufficient': 1216,\n",
       " 'highly': 563,\n",
       " 'material': 732,\n",
       " 'real': 978,\n",
       " 'fall': 422,\n",
       " 'apart': 83,\n",
       " 'expensive': 413,\n",
       " 'gracias': 519,\n",
       " 'second': 1064,\n",
       " 'wore': 1442,\n",
       " 'bit': 145,\n",
       " 'nicer': 791,\n",
       " 'picture': 900,\n",
       " 'held': 557,\n",
       " 'wondered': 1440,\n",
       " 'paper': 872,\n",
       " 'filling': 444,\n",
       " 'inside': 609,\n",
       " 'looking': 697,\n",
       " 'overall': 858,\n",
       " 'people': 882,\n",
       " 'bunion': 183,\n",
       " 'issues': 621,\n",
       " 'previous': 939,\n",
       " 'surgeries': 1228,\n",
       " 'daughter': 307,\n",
       " 'loves': 710,\n",
       " 'class': 224,\n",
       " 'she': 1083,\n",
       " 'cute': 299,\n",
       " 'look': 695,\n",
       " 'zero': 1467,\n",
       " 'wearable': 1395,\n",
       " 'straight': 1201,\n",
       " 'fits': 455,\n",
       " 'comfortably': 249,\n",
       " 'glove': 507,\n",
       " 'bulky': 182,\n",
       " 'hated': 547,\n",
       " 'those': 1273,\n",
       " 'things': 1269,\n",
       " 'lol': 692,\n",
       " 'shot': 1099,\n",
       " 'start': 1185,\n",
       " '12': 3,\n",
       " 'hour': 577,\n",
       " 'shift': 1084,\n",
       " 'also': 66,\n",
       " 'absolute': 30,\n",
       " 'favorite': 433,\n",
       " 'closet': 234,\n",
       " 'knees': 644,\n",
       " 'bothering': 159,\n",
       " 'hiit': 564,\n",
       " 'researching': 1009,\n",
       " 'ellipical': 370,\n",
       " 'tredmill': 1318,\n",
       " 'etc': 388,\n",
       " 'came': 193,\n",
       " 'within': 1434,\n",
       " 'frame': 482,\n",
       " 'given': 504,\n",
       " 'needed': 779,\n",
       " 'job': 630,\n",
       " 'requires': 1007,\n",
       " 'standing': 1182,\n",
       " 'abd': 25,\n",
       " 'throughout': 1278,\n",
       " 'cheap': 213,\n",
       " 'loved': 709,\n",
       " 'consistent': 265,\n",
       " 'photos': 897,\n",
       " 'description': 323,\n",
       " 'accurate': 35,\n",
       " 'try': 1324,\n",
       " 'wanting': 1380,\n",
       " 'satisfied': 1054,\n",
       " 'today': 1295,\n",
       " 'normally': 800,\n",
       " 'an': 73,\n",
       " 'airport': 59,\n",
       " 'omaha': 826,\n",
       " 'ne': 776,\n",
       " 'phoenix': 895,\n",
       " 'az': 108,\n",
       " 'arrived': 94,\n",
       " 'left': 665,\n",
       " 'started': 1186,\n",
       " 'squeaking': 1175,\n",
       " 'won': 1439,\n",
       " 'stop': 1199,\n",
       " 'want': 1378,\n",
       " 'refund': 993,\n",
       " 'instructions': 615,\n",
       " 'returning': 1018,\n",
       " 'paperwork': 873,\n",
       " 'package': 865,\n",
       " 'uncomfortable': 1338,\n",
       " 'soles': 1147,\n",
       " 'squeak': 1174,\n",
       " 'breathe': 172,\n",
       " 'exactly': 399,\n",
       " 'chic': 216,\n",
       " 'gift': 501,\n",
       " 'confortable': 261,\n",
       " 'decent': 311,\n",
       " 'doing': 347,\n",
       " 'regular': 995,\n",
       " 'activity': 44,\n",
       " 'sprinting': 1170,\n",
       " 'smaller': 1134,\n",
       " 'usual': 1353,\n",
       " 'customer': 297,\n",
       " 'service': 1076,\n",
       " 'ive': 626,\n",
       " 'sketchers': 1118,\n",
       " 'walk': 1371,\n",
       " 'fan': 424,\n",
       " 'latest': 661,\n",
       " 'number': 810,\n",
       " 'tread': 1316,\n",
       " 'slippery': 1130,\n",
       " 'grip': 524,\n",
       " 'solid': 1148,\n",
       " 'basic': 123,\n",
       " 'cross': 290,\n",
       " 'massage': 731,\n",
       " 'therapist': 1259,\n",
       " 'through': 1277,\n",
       " 'fast': 430,\n",
       " 'enough': 381,\n",
       " 'recently': 985,\n",
       " 'consolidated': 266,\n",
       " 'offer': 817,\n",
       " 'same': 1052,\n",
       " 'level': 671,\n",
       " 'however': 581,\n",
       " 'kind': 643,\n",
       " 'long': 693,\n",
       " 'term': 1250,\n",
       " 'durable': 360,\n",
       " 'option': 838,\n",
       " 'seem': 1069,\n",
       " 'ideal': 591,\n",
       " '25': 10,\n",
       " '000': 0,\n",
       " 'steps': 1192,\n",
       " 'walt': 1377,\n",
       " 'disney': 342,\n",
       " 'world': 1448,\n",
       " 'wife': 1426,\n",
       " 'extremely': 418,\n",
       " 'artculo': 95,\n",
       " 'equivocado': 385,\n",
       " 'en': 374,\n",
       " 'glad': 505,\n",
       " 'read': 975,\n",
       " 'worked': 1444,\n",
       " 'night': 792,\n",
       " 'anyone': 80,\n",
       " 'beach': 125,\n",
       " 'body': 153,\n",
       " 'coach': 239,\n",
       " 'new': 787,\n",
       " 'slippers': 1129,\n",
       " 'myself': 774,\n",
       " 'christmas': 220,\n",
       " 'amazon': 71,\n",
       " 'card': 199,\n",
       " 'sneakers': 1138,\n",
       " 'telling': 1246,\n",
       " 'friends': 484,\n",
       " 'stained': 1178,\n",
       " 'yellow': 1460,\n",
       " 'spots': 1167,\n",
       " 'iteration': 624,\n",
       " 'earlier': 363,\n",
       " 'finally': 445,\n",
       " 'several': 1081,\n",
       " 'wouldn': 1453,\n",
       " 'going': 511,\n",
       " 'makes': 725,\n",
       " 'hadn': 534,\n",
       " 'realized': 979,\n",
       " 'how': 580,\n",
       " 'until': 1344,\n",
       " 'stay': 1190,\n",
       " 'cool': 275,\n",
       " 'noticeably': 805,\n",
       " 'lasting': 657,\n",
       " 'worn': 1449,\n",
       " 'hiking': 566,\n",
       " 'pinch': 904,\n",
       " 'mesh': 741,\n",
       " 'let': 670,\n",
       " 'dirt': 335,\n",
       " 'mainly': 722,\n",
       " 'something': 1151,\n",
       " 'town': 1306,\n",
       " 'further': 491,\n",
       " 'mine': 749,\n",
       " 'higher': 562,\n",
       " 'pleasantly': 917,\n",
       " 'surprised': 1229,\n",
       " 'circuit': 221,\n",
       " 'couldn': 281,\n",
       " 'tell': 1245,\n",
       " 'pics': 899,\n",
       " 'ran': 970,\n",
       " 'slightly': 1126,\n",
       " '15': 4,\n",
       " 'ago': 57,\n",
       " 'larger': 654,\n",
       " 'hurache': 586,\n",
       " 'worried': 1450,\n",
       " 'actually': 45,\n",
       " 'toe': 1296,\n",
       " 'room': 1031,\n",
       " 'own': 863,\n",
       " 'boot': 155,\n",
       " 'amount': 72,\n",
       " 'edge': 366,\n",
       " 'less': 669,\n",
       " 'jammed': 628,\n",
       " 'lunging': 717,\n",
       " 'jumping': 635,\n",
       " 'odd': 814,\n",
       " 'yellowish': 1461,\n",
       " 'side': 1107,\n",
       " 'damage': 302,\n",
       " 'lining': 685,\n",
       " 'happy': 542,\n",
       " 'clorox': 231,\n",
       " 'wipe': 1430,\n",
       " 'cleaned': 227,\n",
       " 'discolor': 339,\n",
       " 'once': 828,\n",
       " 'balance': 113,\n",
       " 'why': 1422,\n",
       " 'still': 1195,\n",
       " 'cant': 196,\n",
       " 'beat': 126,\n",
       " 'absolutly': 32,\n",
       " 'beautiful': 127,\n",
       " 'noticed': 806,\n",
       " 'foam': 469,\n",
       " 'tends': 1248,\n",
       " 'compress': 258,\n",
       " 'll': 689,\n",
       " 'lace': 648,\n",
       " 'tightly': 1287,\n",
       " 'nearly': 777,\n",
       " 'cutting': 300,\n",
       " 'off': 816,\n",
       " 'circulation': 222,\n",
       " '20': 8,\n",
       " 'minutes': 752,\n",
       " 'later': 659,\n",
       " 'sliding': 1125,\n",
       " 'while': 1418,\n",
       " 'sled': 1120,\n",
       " 'pushes': 963,\n",
       " 'longer': 694,\n",
       " 'usually': 1354,\n",
       " 'could': 280,\n",
       " 'width': 1425,\n",
       " 'pinker': 906,\n",
       " 'shown': 1102,\n",
       " 'gray': 520,\n",
       " 'bright': 174,\n",
       " 'isn': 619,\n",
       " 'overwhelming': 862,\n",
       " 'grommets': 527,\n",
       " 'referring': 992,\n",
       " 'closer': 233,\n",
       " 'photo': 896,\n",
       " 'talking': 1242,\n",
       " 'top': 1303,\n",
       " 'laces': 649,\n",
       " 'opposite': 836,\n",
       " 'thought': 1275,\n",
       " 'faulty': 432,\n",
       " 'pictured': 901,\n",
       " 'keeping': 638,\n",
       " 'can': 195,\n",
       " 'see': 1068,\n",
       " 'coming': 251,\n",
       " 'mile': 746,\n",
       " 'away': 106,\n",
       " 'snug': 1139,\n",
       " 'foot': 471,\n",
       " 'flex': 461,\n",
       " 'wire': 1431,\n",
       " 'tight': 1283,\n",
       " 'your': 1466,\n",
       " 'wiggle': 1427,\n",
       " 'footwear': 473,\n",
       " 'otherwise': 849,\n",
       " 'kept': 639,\n",
       " 'mid': 743,\n",
       " 'section': 1066,\n",
       " 'starts': 1187,\n",
       " 'using': 1352,\n",
       " 'tough': 1305,\n",
       " 'owned': 864,\n",
       " 'line': 683,\n",
       " 'happened': 539,\n",
       " 'narrow': 775,\n",
       " 'stretch': 1203,\n",
       " 'didnt': 329,\n",
       " 'breaking': 169,\n",
       " 'originally': 845,\n",
       " 'tad': 1239,\n",
       " 'wall': 1375,\n",
       " 'swell': 1235,\n",
       " 'concrete': 259,\n",
       " 'impact': 595,\n",
       " 'absorption': 33,\n",
       " 'trail': 1311,\n",
       " 'dance': 303,\n",
       " 'jam': 627,\n",
       " 'zumba': 1469,\n",
       " 'wanted': 1379,\n",
       " 'toes': 1297,\n",
       " 'tingled': 1290,\n",
       " 'went': 1409,\n",
       " 'numb': 809,\n",
       " 'cramped': 287,\n",
       " 'bed': 130,\n",
       " 'lunges': 716,\n",
       " 'ball': 115,\n",
       " 'someone': 1150,\n",
       " 'colors': 243,\n",
       " 'hike': 565,\n",
       " 'blister': 147,\n",
       " 'pinky': 908,\n",
       " 'similar': 1108,\n",
       " 'difficult': 333,\n",
       " 'pressure': 936,\n",
       " 'sensitive': 1073,\n",
       " 'portions': 929,\n",
       " 'her': 559,\n",
       " 'arches': 88,\n",
       " 'calves': 191,\n",
       " 'hunt': 585,\n",
       " 'trainer': 1312,\n",
       " 'lift': 673,\n",
       " 'lightly': 677,\n",
       " 'jog': 631,\n",
       " 'wonderful': 1441,\n",
       " 'womans': 1436,\n",
       " 'almost': 64,\n",
       " 'slips': 1131,\n",
       " 'loose': 700,\n",
       " 'heal': 553,\n",
       " 'tighten': 1284,\n",
       " 'hurting': 588,\n",
       " 'daily': 301,\n",
       " 'cleaning': 228,\n",
       " 'business': 184,\n",
       " 'middle': 744,\n",
       " 'absolutely': 31,\n",
       " 'roughly': 1035,\n",
       " 'miles': 747,\n",
       " '3x': 17,\n",
       " 'per': 883,\n",
       " '3rd': 15,\n",
       " 'exact': 398,\n",
       " 'obsessed': 812,\n",
       " 'bill': 144,\n",
       " 'specifically': 1160,\n",
       " 'court': 284,\n",
       " 'sports': 1164,\n",
       " 'reluctant': 999,\n",
       " 'whether': 1416,\n",
       " 'contact': 270,\n",
       " 'ground': 528,\n",
       " 'supportive': 1223,\n",
       " 'abit': 26,\n",
       " 'rough': 1034,\n",
       " 'oops': 833,\n",
       " 'wrong': 1456,\n",
       " 'sneaker': 1137,\n",
       " 'compliments': 257,\n",
       " 'orthotics': 846,\n",
       " 'found': 480,\n",
       " 'accommodate': 34,\n",
       " 'green': 522,\n",
       " 'show': 1101,\n",
       " 'began': 133,\n",
       " 'falling': 423,\n",
       " 'smooth': 1136,\n",
       " 'floors': 467,\n",
       " 'assume': 98,\n",
       " 'defective': 314,\n",
       " 'ryka': 1048,\n",
       " 'solely': 1146,\n",
       " 'others': 848,\n",
       " 'everyday': 394,\n",
       " 'working': 1445,\n",
       " 'opinion': 835,\n",
       " 'care': 201,\n",
       " 'ugly': 1334,\n",
       " 'rounded': 1037,\n",
       " 'weird': 1407,\n",
       " 'womens': 1438,\n",
       " 'costs': 278,\n",
       " 'luv': 718,\n",
       " 'mind': 748,\n",
       " 'broken': 177,\n",
       " 'attractive': 103,\n",
       " 'seller': 1072,\n",
       " 'delivered': 318,\n",
       " 'sessions': 1078,\n",
       " 'neither': 781,\n",
       " 'nor': 798,\n",
       " 'neon': 782,\n",
       " 'bulk': 181,\n",
       " 'base': 121,\n",
       " 'low': 712,\n",
       " 'cut': 298,\n",
       " 'pushing': 964,\n",
       " 'sleds': 1121,\n",
       " 'traction': 1310,\n",
       " 'group': 529,\n",
       " 'fight': 443,\n",
       " 'quick': 968,\n",
       " 'movements': 765,\n",
       " 'footwork': 474,\n",
       " 'minimally': 751,\n",
       " 'passed': 878,\n",
       " 'meant': 737,\n",
       " 'knock': 646,\n",
       " 'fact': 420,\n",
       " 'former': 479,\n",
       " 'runner': 1045,\n",
       " 'needing': 780,\n",
       " 'spread': 1168,\n",
       " 'roomy': 1032,\n",
       " 'remedy': 1000,\n",
       " 'issue': 620,\n",
       " 'swap': 1231,\n",
       " 'indoor': 604,\n",
       " 'exercises': 408,\n",
       " 'okay': 822,\n",
       " 'sticky': 1194,\n",
       " 'rubber': 1041,\n",
       " 'areas': 91,\n",
       " 'slipped': 1128,\n",
       " 'cable': 189,\n",
       " 'machines': 720,\n",
       " 'resistance': 1010,\n",
       " 'band': 116,\n",
       " 'un': 1335,\n",
       " 'carpeted': 205,\n",
       " 'floor': 466,\n",
       " 'emphasize': 373,\n",
       " 'part': 874,\n",
       " 'routine': 1039,\n",
       " 'lasted': 656,\n",
       " 'six': 1113,\n",
       " 'gave': 494,\n",
       " 'three': 1276,\n",
       " 'perf': 884,\n",
       " 'cam': 192,\n",
       " 'reordered': 1002,\n",
       " 'layer': 662,\n",
       " 'skin': 1119,\n",
       " 'europe': 389,\n",
       " 'socks': 1142,\n",
       " 'tranasaction': 1315,\n",
       " 'impression': 598,\n",
       " 'cushiony': 296,\n",
       " 'firmer': 452,\n",
       " 'refunded': 994,\n",
       " 'instantly': 612,\n",
       " 'upon': 1347,\n",
       " 'credit': 288,\n",
       " 'nothing': 804,\n",
       " 'crossfit': 291,\n",
       " 'month': 757,\n",
       " 'length': 668,\n",
       " 'ugh': 1333,\n",
       " 'man': 727,\n",
       " 'camp': 194,\n",
       " 'picky': 898,\n",
       " 'lack': 651,\n",
       " 'sore': 1157,\n",
       " 'fix': 458,\n",
       " 'regularly': 996,\n",
       " 'exoected': 409,\n",
       " 'row': 1040,\n",
       " 'five': 457,\n",
       " 'exercise': 406,\n",
       " 'allow': 62,\n",
       " 'breath': 170,\n",
       " 'blue': 151,\n",
       " 'airy': 60,\n",
       " 'weightlifting': 1405,\n",
       " 'trial': 1319,\n",
       " 'ventilation': 1358,\n",
       " 'padding': 866,\n",
       " 'minimalist': 750,\n",
       " '40': 18,\n",
       " 'plus': 921,\n",
       " 'certainly': 208,\n",
       " 'done': 349,\n",
       " '100': 2,\n",
       " 'swiss': 1236,\n",
       " 'clients': 229,\n",
       " 'shoelaces': 1093,\n",
       " 'fitting': 456,\n",
       " 'thinner': 1271,\n",
       " 'shipping': 1089,\n",
       " 'happier': 541,\n",
       " 'outs': 855,\n",
       " 'joined': 633,\n",
       " 'adjustment': 49,\n",
       " 'provides': 955,\n",
       " 'grit': 526,\n",
       " 'enjoy': 379,\n",
       " 'distances': 343,\n",
       " 'feels': 437,\n",
       " 'occasion': 813,\n",
       " ...}"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = pipe['counts']\n",
    "vectorizer.vocabulary_ # Entire vocabulary of corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "708"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_.get('love') # Index of given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '10',\n",
       " '100',\n",
       " '12',\n",
       " '15',\n",
       " '159',\n",
       " '169lbs',\n",
       " '1st',\n",
       " '20',\n",
       " '24',\n",
       " '25',\n",
       " '257lbs',\n",
       " '2nd',\n",
       " '30',\n",
       " '34',\n",
       " '3rd',\n",
       " '3s',\n",
       " '3x',\n",
       " '40',\n",
       " '50',\n",
       " '54',\n",
       " '6th',\n",
       " '90',\n",
       " '99',\n",
       " 'abbey',\n",
       " 'abd',\n",
       " 'abit',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutly',\n",
       " 'absorption',\n",
       " 'accommodate',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'ache',\n",
       " 'ached',\n",
       " 'aches',\n",
       " 'achilles',\n",
       " 'aching',\n",
       " 'active',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'adding',\n",
       " 'adjust',\n",
       " 'adjustment',\n",
       " 'advice',\n",
       " 'aerobic',\n",
       " 'aerobics',\n",
       " 'afford',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'again',\n",
       " 'ago',\n",
       " 'aide',\n",
       " 'airport',\n",
       " 'airy',\n",
       " 'all',\n",
       " 'allow',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazing',\n",
       " 'amazon',\n",
       " 'amount',\n",
       " 'an',\n",
       " 'and',\n",
       " 'ankle',\n",
       " 'annoying',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'apart',\n",
       " 'appear',\n",
       " 'appears',\n",
       " 'appropriate',\n",
       " 'arch',\n",
       " 'arches',\n",
       " 'are',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'arose',\n",
       " 'around',\n",
       " 'arrived',\n",
       " 'artculo',\n",
       " 'as',\n",
       " 'asics',\n",
       " 'assume',\n",
       " 'at',\n",
       " 'athleta',\n",
       " 'athletic',\n",
       " 'attention',\n",
       " 'attractive',\n",
       " 'available',\n",
       " 'average',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'az',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'bag',\n",
       " 'bailing',\n",
       " 'balance',\n",
       " 'balances',\n",
       " 'ball',\n",
       " 'band',\n",
       " 'bandage',\n",
       " 'barefeet',\n",
       " 'barefoot',\n",
       " 'barely',\n",
       " 'base',\n",
       " 'based',\n",
       " 'basic',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'beat',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'because',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'before',\n",
       " 'began',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'below',\n",
       " 'bend',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'bill',\n",
       " 'bit',\n",
       " 'black',\n",
       " 'blister',\n",
       " 'blisters',\n",
       " 'blood',\n",
       " 'blown',\n",
       " 'blue',\n",
       " 'bluffs',\n",
       " 'body',\n",
       " 'bone',\n",
       " 'boot',\n",
       " 'bootcamps',\n",
       " 'both',\n",
       " 'bother',\n",
       " 'bothering',\n",
       " 'bothers',\n",
       " 'bottom',\n",
       " 'bottoms',\n",
       " 'bought',\n",
       " 'box',\n",
       " 'boxier',\n",
       " 'brand',\n",
       " 'brands',\n",
       " 'break',\n",
       " 'breaking',\n",
       " 'breath',\n",
       " 'breathable',\n",
       " 'breathe',\n",
       " 'breathes',\n",
       " 'bright',\n",
       " 'broader',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'btw',\n",
       " 'build',\n",
       " 'built',\n",
       " 'bulk',\n",
       " 'bulky',\n",
       " 'bunion',\n",
       " 'business',\n",
       " 'but',\n",
       " 'buy',\n",
       " 'buying',\n",
       " 'by',\n",
       " 'cable',\n",
       " 'calf',\n",
       " 'calves',\n",
       " 'cam',\n",
       " 'came',\n",
       " 'camp',\n",
       " 'can',\n",
       " 'cant',\n",
       " 'capris',\n",
       " 'carbide',\n",
       " 'card',\n",
       " 'cardio',\n",
       " 'care',\n",
       " 'careful',\n",
       " 'carefully',\n",
       " 'carpet',\n",
       " 'carpeted',\n",
       " 'casual',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changing',\n",
       " 'chart',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'check',\n",
       " 'chic',\n",
       " 'child',\n",
       " 'children',\n",
       " 'choice',\n",
       " 'christmas',\n",
       " 'circuit',\n",
       " 'circulation',\n",
       " 'cl',\n",
       " 'class',\n",
       " 'classes',\n",
       " 'clean',\n",
       " 'cleaned',\n",
       " 'cleaning',\n",
       " 'clients',\n",
       " 'climates',\n",
       " 'clorox',\n",
       " 'closed',\n",
       " 'closer',\n",
       " 'closet',\n",
       " 'clothes',\n",
       " 'cloud',\n",
       " 'clown',\n",
       " 'clunkier',\n",
       " 'coach',\n",
       " 'color',\n",
       " 'colored',\n",
       " 'colorful',\n",
       " 'colors',\n",
       " 'colour',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comfort',\n",
       " 'comfortable',\n",
       " 'comfortably',\n",
       " 'comfy',\n",
       " 'coming',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'complains',\n",
       " 'complaint',\n",
       " 'completely',\n",
       " 'compliments',\n",
       " 'compress',\n",
       " 'concrete',\n",
       " 'condition',\n",
       " 'confortable',\n",
       " 'consider',\n",
       " 'consideration',\n",
       " 'considering',\n",
       " 'consistent',\n",
       " 'consolidated',\n",
       " 'constant',\n",
       " 'constantly',\n",
       " 'constructed',\n",
       " 'contact',\n",
       " 'content',\n",
       " 'continue',\n",
       " 'continues',\n",
       " 'cooked',\n",
       " 'cool',\n",
       " 'coral',\n",
       " 'correct',\n",
       " 'costs',\n",
       " 'costume',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'court',\n",
       " 'coverage',\n",
       " 'cradled',\n",
       " 'cramped',\n",
       " 'credit',\n",
       " 'crimson',\n",
       " 'cross',\n",
       " 'crossfit',\n",
       " 'crosstrainers',\n",
       " 'cushion',\n",
       " 'cushioned',\n",
       " 'cushioning',\n",
       " 'cushiony',\n",
       " 'customer',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cutting',\n",
       " 'daily',\n",
       " 'damage',\n",
       " 'dance',\n",
       " 'dancing',\n",
       " 'dark',\n",
       " 'date',\n",
       " 'daughter',\n",
       " 'daughters',\n",
       " 'day',\n",
       " 'days',\n",
       " 'decent',\n",
       " 'deep',\n",
       " 'deeper',\n",
       " 'defective',\n",
       " 'definetly',\n",
       " 'definitely',\n",
       " 'degree',\n",
       " 'delivered',\n",
       " 'delivery',\n",
       " 'depends',\n",
       " 'depict',\n",
       " 'described',\n",
       " 'description',\n",
       " 'design',\n",
       " 'detail',\n",
       " 'developed',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'didnt',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'differently',\n",
       " 'difficult',\n",
       " 'difficulty',\n",
       " 'dirt',\n",
       " 'dirty',\n",
       " 'disappear',\n",
       " 'disappointed',\n",
       " 'discolor',\n",
       " 'discomfort',\n",
       " 'discontinues',\n",
       " 'disney',\n",
       " 'distances',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'done',\n",
       " 'down',\n",
       " 'downshifter',\n",
       " 'downton',\n",
       " 'drag',\n",
       " 'dream',\n",
       " 'dress',\n",
       " 'dressy',\n",
       " 'dropped',\n",
       " 'dry',\n",
       " 'dsw',\n",
       " 'durable',\n",
       " 'during',\n",
       " 'each',\n",
       " 'earlier',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'edge',\n",
       " 'edges',\n",
       " 'effortlessly',\n",
       " 'elastics',\n",
       " 'ellipical',\n",
       " 'else',\n",
       " 'em',\n",
       " 'emphasize',\n",
       " 'en',\n",
       " 'end',\n",
       " 'ended',\n",
       " 'endurance',\n",
       " 'engagement',\n",
       " 'enjoy',\n",
       " 'enjoyed',\n",
       " 'enough',\n",
       " 'entire',\n",
       " 'entirely',\n",
       " 'environment',\n",
       " 'equivocado',\n",
       " 'especially',\n",
       " 'estimated',\n",
       " 'etc',\n",
       " 'europe',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyday',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'exact',\n",
       " 'exactly',\n",
       " 'excelente',\n",
       " 'excellent',\n",
       " 'except',\n",
       " 'exception',\n",
       " 'exchange',\n",
       " 'excited',\n",
       " 'exercise',\n",
       " 'exercised',\n",
       " 'exercises',\n",
       " 'exoected',\n",
       " 'expect',\n",
       " 'expected',\n",
       " 'expecting',\n",
       " 'expensive',\n",
       " 'experience',\n",
       " 'experienced',\n",
       " 'extended',\n",
       " 'extra',\n",
       " 'extremely',\n",
       " 'fabric',\n",
       " 'fact',\n",
       " 'fade',\n",
       " 'fall',\n",
       " 'falling',\n",
       " 'fan',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'fasciitis',\n",
       " 'fascitis',\n",
       " 'fashion',\n",
       " 'fast',\n",
       " 'fault',\n",
       " 'faulty',\n",
       " 'favorite',\n",
       " 'favorites',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'feels',\n",
       " 'feet',\n",
       " 'fella',\n",
       " 'felt',\n",
       " 'few',\n",
       " 'fiber',\n",
       " 'fight',\n",
       " 'filling',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'finding',\n",
       " 'fine',\n",
       " 'fingers',\n",
       " 'finish',\n",
       " 'fireman',\n",
       " 'firmer',\n",
       " 'first',\n",
       " 'fit',\n",
       " 'fits',\n",
       " 'fitting',\n",
       " 'five',\n",
       " 'fix',\n",
       " 'flat',\n",
       " 'flattering',\n",
       " 'flex',\n",
       " 'flexibility',\n",
       " 'flexible',\n",
       " 'flezable',\n",
       " 'flimsy',\n",
       " 'floor',\n",
       " 'floors',\n",
       " 'fly',\n",
       " 'foam',\n",
       " 'fog',\n",
       " 'foot',\n",
       " 'footbed',\n",
       " 'footwear',\n",
       " 'footwork',\n",
       " 'for',\n",
       " 'force',\n",
       " 'forest',\n",
       " 'forget',\n",
       " 'former',\n",
       " 'found',\n",
       " 'four',\n",
       " 'frame',\n",
       " 'free',\n",
       " 'friends',\n",
       " 'frills',\n",
       " 'from',\n",
       " 'front',\n",
       " 'fruit',\n",
       " 'full',\n",
       " 'fun',\n",
       " 'further',\n",
       " 'futur',\n",
       " 'future',\n",
       " 'gave',\n",
       " 'geared',\n",
       " 'generally',\n",
       " 'generation',\n",
       " 'generations',\n",
       " 'get',\n",
       " 'getting',\n",
       " 'gift',\n",
       " 'girlfriend',\n",
       " 'give',\n",
       " 'given',\n",
       " 'glad',\n",
       " 'glasses',\n",
       " 'glove',\n",
       " 'gloves',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gold',\n",
       " 'gone',\n",
       " 'good',\n",
       " 'goods',\n",
       " 'gorgeous',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'gracias',\n",
       " 'gray',\n",
       " 'great',\n",
       " 'green',\n",
       " 'grey',\n",
       " 'grip',\n",
       " 'grips',\n",
       " 'grit',\n",
       " 'grommets',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'gry',\n",
       " 'gump',\n",
       " 'gym',\n",
       " 'had',\n",
       " 'hadn',\n",
       " 'half',\n",
       " 'handy',\n",
       " 'hanes',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'happens',\n",
       " 'happier',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'has',\n",
       " 'hat',\n",
       " 'hate',\n",
       " 'hated',\n",
       " 'havaiana',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'he',\n",
       " 'heal',\n",
       " 'heavy',\n",
       " 'heel',\n",
       " 'heels',\n",
       " 'held',\n",
       " 'help',\n",
       " 'her',\n",
       " 'here',\n",
       " 'high',\n",
       " 'higher',\n",
       " 'highly',\n",
       " 'hiit',\n",
       " 'hike',\n",
       " 'hiking',\n",
       " 'him',\n",
       " 'hip',\n",
       " 'his',\n",
       " 'hitt',\n",
       " 'hold',\n",
       " 'home',\n",
       " 'hop',\n",
       " 'hope',\n",
       " 'hoping',\n",
       " 'hot',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hue',\n",
       " 'hug',\n",
       " 'huge',\n",
       " 'hunt',\n",
       " 'hurache',\n",
       " 'hurt',\n",
       " 'hurting',\n",
       " 'hurts',\n",
       " 'husband',\n",
       " 'ideal',\n",
       " 'if',\n",
       " 'im',\n",
       " 'image',\n",
       " 'impact',\n",
       " 'importantly',\n",
       " 'impressed',\n",
       " 'impression',\n",
       " 'in',\n",
       " 'inch',\n",
       " 'inches',\n",
       " 'incredibly',\n",
       " 'individual',\n",
       " 'indoor',\n",
       " 'initially',\n",
       " 'inseam',\n",
       " 'insert',\n",
       " 'inserts',\n",
       " 'inside',\n",
       " 'insole',\n",
       " 'insoles',\n",
       " 'instantly',\n",
       " 'instead',\n",
       " 'instep',\n",
       " 'instructions',\n",
       " 'intended',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " 'issue',\n",
       " 'issues',\n",
       " 'it',\n",
       " 'item',\n",
       " 'iteration',\n",
       " 'its',\n",
       " 'ive',\n",
       " 'jam',\n",
       " 'jammed',\n",
       " 'jeans',\n",
       " 'job',\n",
       " 'jog',\n",
       " 'jogging',\n",
       " 'joined',\n",
       " 'joint',\n",
       " 'jumping',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'keeping',\n",
       " 'kept',\n",
       " 'kick',\n",
       " 'kickboxing',\n",
       " 'kill',\n",
       " 'kind',\n",
       " 'knees',\n",
       " 'knew',\n",
       " 'knock',\n",
       " 'know',\n",
       " 'lace',\n",
       " 'laces',\n",
       " 'lacing',\n",
       " 'lack',\n",
       " 'large',\n",
       " 'largely',\n",
       " 'larger',\n",
       " 'last',\n",
       " 'lasted',\n",
       " 'lasting',\n",
       " 'late',\n",
       " 'later',\n",
       " 'lateral',\n",
       " 'latest',\n",
       " 'layer',\n",
       " 'learned',\n",
       " 'least',\n",
       " 'left',\n",
       " 'leg',\n",
       " 'legs',\n",
       " 'length',\n",
       " 'less',\n",
       " 'let',\n",
       " 'level',\n",
       " 'life',\n",
       " 'lift',\n",
       " 'lifting',\n",
       " 'light',\n",
       " 'lighter',\n",
       " 'lightly',\n",
       " 'lightweight',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'likes',\n",
       " 'limping',\n",
       " 'line',\n",
       " 'lines',\n",
       " 'lining',\n",
       " 'listened',\n",
       " 'literally',\n",
       " 'little',\n",
       " 'll',\n",
       " 'llt',\n",
       " 'local',\n",
       " 'lol',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'looked',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'loom',\n",
       " 'loose',\n",
       " 'loosens',\n",
       " 'looser',\n",
       " 'lose',\n",
       " 'lot',\n",
       " 'lots',\n",
       " 'lounge',\n",
       " 'lounging',\n",
       " 'love',\n",
       " 'loved',\n",
       " 'loves',\n",
       " 'loving',\n",
       " 'low',\n",
       " 'lower',\n",
       " 'luckily',\n",
       " 'lululemon',\n",
       " 'lunges',\n",
       " 'lunging',\n",
       " 'luv',\n",
       " 'ma',\n",
       " 'machines',\n",
       " 'made',\n",
       " 'mainly',\n",
       " 'major',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'male',\n",
       " 'man',\n",
       " 'manufacturer',\n",
       " 'many',\n",
       " 'marathon',\n",
       " 'massage',\n",
       " 'material',\n",
       " 'matter',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'meant',\n",
       " 'medium',\n",
       " 'meh',\n",
       " 'mens',\n",
       " 'mesh',\n",
       " 'mic',\n",
       " 'mid',\n",
       " 'middle',\n",
       " 'might',\n",
       " 'mile',\n",
       " 'miles',\n",
       " 'mind',\n",
       " 'mine',\n",
       " 'minimalist',\n",
       " 'minimally',\n",
       " 'minutes',\n",
       " 'mirror',\n",
       " 'mizuno',\n",
       " 'moderate',\n",
       " 'money',\n",
       " 'month',\n",
       " 'months',\n",
       " 'more',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'motivation',\n",
       " 'move',\n",
       " 'movement',\n",
       " 'movements',\n",
       " 'movrment',\n",
       " 'mtllc',\n",
       " 'much',\n",
       " 'mud',\n",
       " 'multiple',\n",
       " 'muscle',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'narrow',\n",
       " 'ne',\n",
       " 'nearly',\n",
       " 'need',\n",
       " 'needed',\n",
       " 'needing',\n",
       " 'neither',\n",
       " 'neon',\n",
       " 'neoprene',\n",
       " 'nervous',\n",
       " 'neuromas',\n",
       " 'never',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nice',\n",
       " 'nicely',\n",
       " 'nicer',\n",
       " 'night',\n",
       " 'nike',\n",
       " 'nikes',\n",
       " 'no',\n",
       " 'noise',\n",
       " 'non',\n",
       " 'nor',\n",
       " 'normal',\n",
       " 'normally',\n",
       " 'nose',\n",
       " 'not',\n",
       " 'note',\n",
       " 'nothing',\n",
       " 'noticeably',\n",
       " 'noticed',\n",
       " 'now',\n",
       " 'nubs',\n",
       " 'numb',\n",
       " 'number',\n",
       " 'nyc',\n",
       " 'obsessed',\n",
       " 'occasion',\n",
       " 'odd',\n",
       " 'of',\n",
       " 'off',\n",
       " 'offer',\n",
       " 'office',\n",
       " 'oh',\n",
       " 'ohio',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'ol',\n",
       " 'old',\n",
       " 'older',\n",
       " 'omaha',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'online',\n",
       " 'only',\n",
       " 'oops',\n",
       " 'opened',\n",
       " 'opinion',\n",
       " 'opposite',\n",
       " 'optimal',\n",
       " 'option',\n",
       " 'or',\n",
       " 'orange',\n",
       " 'order',\n",
       " 'ordered',\n",
       " 'ordering',\n",
       " 'original',\n",
       " 'originally',\n",
       " 'orthotics',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'out',\n",
       " 'outdoor',\n",
       " 'outdoors',\n",
       " 'outfits',\n",
       " 'outs',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'overly',\n",
       " 'overpriced',\n",
       " 'oversized',\n",
       " 'overwhelming',\n",
       " 'own',\n",
       " 'owned',\n",
       " 'package',\n",
       " 'padding',\n",
       " 'pain',\n",
       " 'pains',\n",
       " 'pair',\n",
       " 'pairs',\n",
       " 'pants',\n",
       " 'paper',\n",
       " 'paperwork',\n",
       " 'part',\n",
       " 'participate',\n",
       " 'particular',\n",
       " 'particularly',\n",
       " 'passed',\n",
       " 'past',\n",
       " 'pattern',\n",
       " 'pay',\n",
       " 'people',\n",
       " 'per',\n",
       " 'perf',\n",
       " 'perfect',\n",
       " 'perfectly',\n",
       " 'perfict',\n",
       " 'performance',\n",
       " 'performed',\n",
       " 'periods',\n",
       " 'person',\n",
       " 'personal',\n",
       " 'personally',\n",
       " 'perspiration',\n",
       " 'phoenix',\n",
       " 'photo',\n",
       " 'photos',\n",
       " 'picky',\n",
       " 'pics',\n",
       " 'picture',\n",
       " 'pictured',\n",
       " 'pictures',\n",
       " 'pieces',\n",
       " 'pinch',\n",
       " 'pink',\n",
       " 'pinker',\n",
       " 'pinkie',\n",
       " 'pinky',\n",
       " 'pinnacle',\n",
       " 'place',\n",
       " 'placed',\n",
       " 'plain',\n",
       " 'planks',\n",
       " 'plantar',\n",
       " 'plastic',\n",
       " 'plate',\n",
       " 'pleasantly',\n",
       " 'please',\n",
       " 'pleased',\n",
       " 'plenty',\n",
       " 'plus',\n",
       " 'pnk',\n",
       " 'pockets',\n",
       " 'podiatrist',\n",
       " 'point',\n",
       " 'pointier',\n",
       " 'pointing',\n",
       " 'poorly',\n",
       " 'portions',\n",
       " 'possibly',\n",
       " 'pounds',\n",
       " 'powerstep',\n",
       " 'preference',\n",
       " 'pregnant',\n",
       " 'pressing',\n",
       " 'pressure',\n",
       " 'prettier',\n",
       " 'pretty',\n",
       " 'previous',\n",
       " 'price',\n",
       " 'print',\n",
       " 'prior',\n",
       " 'private',\n",
       " 'probably',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'product',\n",
       " 'products',\n",
       " 'profile',\n",
       " 'pronation',\n",
       " 'proper',\n",
       " 'protech',\n",
       " 'provide',\n",
       " 'provided',\n",
       " 'provides',\n",
       " 'pull',\n",
       " 'puma',\n",
       " 'purchase',\n",
       " 'purchased',\n",
       " 'purchasing',\n",
       " 'purpose',\n",
       " 'push',\n",
       " 'pushes',\n",
       " 'pushing',\n",
       " 'put',\n",
       " 'pw',\n",
       " 'quality',\n",
       " 'quick',\n",
       " 'quite',\n",
       " 'ran',\n",
       " 'rarely',\n",
       " 'rather',\n",
       " 're',\n",
       " 'reaches',\n",
       " 'read',\n",
       " 'reading',\n",
       " 'ready',\n",
       " 'real',\n",
       " 'realized',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'reasonable',\n",
       " 'reccomend',\n",
       " 'received',\n",
       " 'recently',\n",
       " 'recess',\n",
       " 'recomend',\n",
       " 'recommend',\n",
       " 'recommended',\n",
       " 'red',\n",
       " 'refer',\n",
       " 'referring',\n",
       " 'refund',\n",
       " 'refunded',\n",
       " 'regular',\n",
       " 'regularly',\n",
       " 'relay',\n",
       " 'relieved',\n",
       " 'reluctant',\n",
       " ...]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.86141913, 5.56213615, 6.75605862, ..., 6.86141913, 6.86141913,\n",
       "       5.34507165])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf = pipe['idf']\n",
    "idf.idf_ # idf of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3160x1470 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 60593 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = idf.transform(vectorizer.transform(docs))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3160x1470 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 60593 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = (ratings == 5) | (ratings == 4)\n",
    "neutral = (ratings == 3)\n",
    "negative = (ratings == 1) | (ratings == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[positive] = 2\n",
    "ratings[neutral] = 1\n",
    "ratings[negative] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 210\n",
      "1.0 337\n",
      "2.0 2613\n"
     ]
    }
   ],
   "source": [
    "for rating in np.unique(ratings):\n",
    "    print(rating, ratings[ratings == rating].size) # Huge disparities in positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9468354430379747"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB().fit(X_train, ratings.ravel())\n",
    "mnb.score(X, ratings.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_trans(pipe, string):\n",
    "    return pipe['idf'].transform(pipe['counts'].transform(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_pred = pipe_trans(pipe, ['This product is really good!'])\n",
    "neg_pred = pipe_trans(pipe, ['This product is terrible!'])\n",
    "neutral_pred = pipe_trans(pipe, ['This is average'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(pos_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(neg_pred) # Misclassifies negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(neutral_pred) # Misclassifies neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9667721518987342"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnb = ComplementNB().fit(X_train, ratings.ravel())\n",
    "cnb.score(X, ratings.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnb.predict(pos_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnb.predict(neutral_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnb.predict(neg_pred) # Misclassifies negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary is likely too small for any good predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.219186755264413\n",
      "[0. 1. 2. 3. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('./data/movies_reviews.hdf5', 'r') as f:\n",
    "    movie_reviews = f['movies_review_text']\n",
    "    movie_ratings = f['movies_ratings']\n",
    "    print(np.mean(movie_ratings)) # Still extremely positive\n",
    "    print(np.unique(movie_ratings))\n",
    "    split_ratings = []\n",
    "    for rating in range(6):\n",
    "        split_ratings.append(movie_ratings[movie_ratings[:] == rating].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These ratings can go from 0-5 rather than 1-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "rating_compare = ax.bar(uni, split_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "categorized_ratings = np.array([sum(split_ratings[0:3]), split_ratings[3], sum(split_ratings[4:])])\n",
    "for ind, bar in enumerate(categorized_ratings):\n",
    "    ax.bar(ind, bar, width=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_arr(arr):\n",
    "    arr = np.asarray(arr)\n",
    "    \n",
    "    # Conditions to categorize reviews\n",
    "    positive = (arr == 5) | (arr == 4)\n",
    "    neutral = (arr == 3)\n",
    "    negative = (arr == 0) | (arr == 1) | (arr == 2)\n",
    "    \n",
    "    # Setting ratings to grouped values\n",
    "    arr[positive] = 2\n",
    "    arr[neutral] = 1\n",
    "    arr[negative] = 0\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data and training model\n",
    "def train_model(estimators, file, validate=False, folds=5, test_size=0.2, start=None, end=None):\n",
    "    \"\"\"\n",
    "    Training sentiment analysis model using\n",
    "    given estimators and a file containing\n",
    "    the dataset. Also performs rudimentary\n",
    "    metrics such as scoring.\n",
    "    \n",
    "    Params\n",
    "    ----\n",
    "    \n",
    "    estimators: list of tuples,\n",
    "        Contains the estimators' string identifier and the\n",
    "        estimator itself. Used to construct a pipeline.\n",
    "    \n",
    "    file: string.\n",
    "        Path of the hdf5 file.\n",
    "        \n",
    "        NOTE: datasets must be in the order of \"ratings\"\n",
    "        and \"review_text\".\n",
    "    \n",
    "    validate: bool, default=False.\n",
    "        If true the model is trained through cross-validation \n",
    "        using the sklearn cross_validate function. \n",
    "        \n",
    "        NOTE: Not suitable for very large datasets. \n",
    "        Performance implications are present.\n",
    "    \n",
    "    folds: int, default=5.\n",
    "        Determines the number of fold/splits used\n",
    "        in cross validation.\n",
    "        \n",
    "    test_size: float, default=0.2.\n",
    "        Determines size of the test set when using the\n",
    "        train_test_split function for model testing.\n",
    "    \n",
    "    Returns\n",
    "    ----\n",
    "    \n",
    "    clf: sklearn.pipeline Pipeline\n",
    "        Pipeline containing estimators passed from\n",
    "        the estimators parameter. Mean to be saved\n",
    "        to disk using joblib.\n",
    "        \n",
    "    metrics: list, shape(2)\n",
    "         Contains the scoring metrics evaluated off\n",
    "         of the test set. score method calculated\n",
    "         from X_test and y_test, and balanced_accuracy_score\n",
    "         method calculated from y_pred and y_test.\n",
    "    \n",
    "    score: dict\n",
    "        Returned from cross_validate function.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    with h5py.File(file, 'r') as f:\n",
    "        keys = list(f.keys())\n",
    "        ratings = f[keys[0]]\n",
    "        corpus = f[keys[1]]\n",
    "        clf = Pipeline(estimators)\n",
    "        categorize = FunctionTransformer(categorize_arr)\n",
    "        \n",
    "        if validate is False:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                corpus[start: end].ravel(),\n",
    "                categorize.transform(ratings[start: end].ravel()),\n",
    "                test_size=test_size,\n",
    "                random_state=42\n",
    "            )\n",
    "            with joblib.parallel_backend('threading', n_jobs=-1):\n",
    "                joblib.Parallel(verbose=10)(joblib.delayed(clf.fit)(X_train, y_train) for i in range(1))\n",
    "            y_pred = clf.predict(X_test)\n",
    "            metrics = [clf.score(X_test, y_test), balanced_accuracy_score(y_test, y_pred)]\n",
    "            return clf, metrics\n",
    "        \n",
    "        if validate is True:\n",
    "            X = corpus[start: end].ravel()\n",
    "            y = categorize.transform(ratings[start: end].ravel())\n",
    "            score = cross_validate(clf, X, y, cv=folds, return_estimator=True, n_jobs=-1)\n",
    "            return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8307517257963296\n"
     ]
    }
   ],
   "source": [
    "cnb_est = [('idf', TfidfVectorizer()), ('cnb', ComplementNB())]\n",
    "#cnb = train_idf(ComplementNB(), './data/movies_reviews.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_est = [('idf', TfidfVectorizer()), ('mnb', MultinomialNB())]\n",
    "#mnb = train(MultinomialNB(), './data/movies_reviews.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnb.predict(['This is great my guy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cnb.joblib']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing models\n",
    "joblib.dump(cnb, 'models/cnb.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mnb.joblib']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mnb, 'models/mnb.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cnb = joblib.load('models/cnb.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cnb.predict(['My guy this is great'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9685534591194969\n"
     ]
    }
   ],
   "source": [
    "# Testing cross val\n",
    "with h5py.File('./data/fashion_reviews.hdf5', 'r') as f:\n",
    "    ratings = f['fashion_ratings']\n",
    "    corpus = f['fashion_review_text']\n",
    "    pipe = make_pipeline(TfidfVectorizer(), ComplementNB())\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        corpus[:].ravel(),\n",
    "        categorize_arr(ratings),\n",
    "        test_size=0.2\n",
    "    )\n",
    "    vec = pipe['tfidfvectorizer']\n",
    "    X_train = vec.fit_transform(X_train)\n",
    "    X_test = vec.transform(X_test)\n",
    "    this_cnb = ComplementNB().fit(X_train, y_train.ravel())\n",
    "    print(this_cnb.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_cnb.predict(vec.transform(['Horribly bad']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.05877709, 0.05282879, 0.0542841 , 0.05296206, 0.05392694]), 'score_time': array([0.0124948 , 0.0142343 , 0.01321507, 0.01396799, 0.01395512]), 'estimator': (Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
      "                ('complementnb', ComplementNB())]), Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
      "                ('complementnb', ComplementNB())]), Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
      "                ('complementnb', ComplementNB())]), Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
      "                ('complementnb', ComplementNB())]), Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
      "                ('complementnb', ComplementNB())])), 'test_score': array([0.90408805, 0.97637795, 0.97795276, 0.96377953, 0.97165354])}\n"
     ]
    }
   ],
   "source": [
    "# Testing cross val\n",
    "with h5py.File('./data/fashion_reviews.hdf5', 'r') as f:\n",
    "    ratings = f['fashion_ratings']\n",
    "    corpus = f['fashion_review_text']\n",
    "    clf = make_pipeline(TfidfVectorizer(), ComplementNB())\n",
    "    X = corpus[:].ravel()\n",
    "    y = categorize_arr(ratings).ravel()\n",
    "    score = cross_validate(clf, X, y, cv=5, return_estimator=True)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   53.0s\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   53.0s finished\n"
     ]
    }
   ],
   "source": [
    "n_grams = [('idf', TfidfVectorizer(ngram_range=(1, 2))), ('cnb', ComplementNB())]\n",
    "cnb_ngrams, metrics = train_model(n_grams, './data/movies_reviews.hdf5', end=200_000)\n",
    "#joblib.dump(cnb_ngrams, './models/cnb_bigrams.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Pipeline(steps=[('idf', TfidfVectorizer(ngram_range=(1, 2))),\n",
       "                 ('cnb', ComplementNB())]),\n",
       " [0.83955, 0.3546432999718309])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnb_ngrams, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnb_ngrams.predict(['Bad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    6.5s finished\n"
     ]
    }
   ],
   "source": [
    "bow = [('idf', TfidfVectorizer()), ('cnb', ComplementNB())]\n",
    "cnb_bow, bow_metrics = train_model(bow, './data/movies_reviews.hdf5', end=100_000)\n",
    "#joblib.dump(cnb_ngrams, './models/cnb_bigrams.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Pipeline(steps=[('idf', TfidfVectorizer()), ('cnb', ComplementNB())]),\n",
       " [0.84345, 0.3865749121431774])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnb_bow, bow_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnb_bow.predict(['This is very terrible'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'partial_fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-987ba55448da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_ind\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategorize_arr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_ind\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mcurr_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'partial_fit'"
     ]
    }
   ],
   "source": [
    "# Testing cross val\n",
    "with h5py.File('./data/movies_reviews.hdf5', 'r') as f:\n",
    "    keys = list(f.keys())\n",
    "    ratings = f[keys[0]]\n",
    "    corpus = f[keys[1]]\n",
    "    pipe = make_pipeline(TfidfVectorizer(), ComplementNB())\n",
    "    curr_ind = 0\n",
    "    for _ in range(50):\n",
    "        end = curr_ind + 1000\n",
    "        X_train = corpus[curr_ind: end].ravel()\n",
    "        y_train = categorize_arr(ratings[curr_ind: end]).ravel()\n",
    "        pipe.partial_fit(X_train, y_train)\n",
    "        curr_ind = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func():\n",
    "    with h5py.File('./data/movies_reviews.hdf5', 'r') as f:\n",
    "        keys = list(f.keys())\n",
    "        ratings = f[keys[0]]\n",
    "        corpus = f[keys[1]]\n",
    "        clf = make_pipeline(TfidfVectorizer(ngram_range=(1, 2)), ComplementNB())\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            corpus[:500_000].ravel(),\n",
    "            categorize_arr(ratings[:500_000].ravel()),\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(clf.score(X_test, y_test), balanced_accuracy_score(y_test, y_pred))\n",
    "        return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82715 0.3618662771486533\n"
     ]
    }
   ],
   "source": [
    "clf = test_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.23 s ± 10.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "n_grams = [('idf', TfidfVectorizer(ngram_range=(1, 2))), ('cnb', ComplementNB())]\n",
    "%timeit train_model(n_grams, './data/movies_reviews.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parallel(estimators):\n",
    "    with h5py.File('./data/movies_reviews.hdf5', 'r') as f:\n",
    "        keys = list(f.keys())\n",
    "        ratings = f[keys[0]]\n",
    "        corpus = f[keys[1]]\n",
    "        clf = Pipeline(estimators)\n",
    "        categorize = FunctionTransformer(categorize_arr)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            corpus[:10_000].ravel(),\n",
    "            categorize.transform(ratings[:10_000].ravel()),\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        with joblib.parallel_backend('threading', n_jobs=-1):\n",
    "            joblib.Parallel(verbose=10)(joblib.delayed(clf.fit)(X_train, y_train) for i in range(1))\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(clf.score(X_test, y_test))\n",
    "        return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8245\n",
      "3.38 s ± 24.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit test_parallel(n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8245\n",
      "0.8245\n",
      "0.8245\n",
      "0.8245\n",
      "0.8245\n",
      "0.8245\n",
      "0.8245\n",
      "0.8245\n",
      "3.38 s ± 71.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit test_parallel(n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    3.8s finished\n"
     ]
    }
   ],
   "source": [
    "with joblib.parallel_backend('threading', n_jobs=-1):\n",
    "    joblib.Parallel(verbose=10)(joblib.delayed(test_parallel)(n_grams) for i in range(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('./data/movies_reviews.hdf5', 'r') as f:\n",
    "    keys = list(f.keys())\n",
    "    ratings = f[keys[0]]\n",
    "    corpus = f[keys[1]]\n",
    "    rate = categorize_arr(ratings[0:1_000_000]).ravel()\n",
    "    corp = corpus[0: 1_000_000].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = corp[rate == 0]\n",
    "neutral = corp[rate == 1]\n",
    "filtered_pos = corp[rate == 2][0:100_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate([np.full(negatives.shape, 0.), np.full(neutral.shape, 1), np.full(filtered_pos.shape, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([negatives, neutral, filtered_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_test(X, y):\n",
    "    balanced_clf = make_pipeline(TfidfVectorizer(), ComplementNB())\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    with joblib.parallel_backend('threading', n_jobs=-1):\n",
    "        joblib.Parallel(verbose=10)(joblib.delayed(clf.fit)(X_train, y_train) for i in range(1))\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.score(X_test, y_test), balanced_accuracy_score(y_test, y_pred))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7264696871702352 0.7263743738048264\n"
     ]
    }
   ],
   "source": [
    "bal_cnb = balance_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bal_cnb.predict(['I really hate these movies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/bal_cnb_bigrams.joblib']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(bal_cnb, './models/bal_cnb_bigrams.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_cnb = joblib.load('./models/cnb_bow.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6330719007645541"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_cnb.score(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
